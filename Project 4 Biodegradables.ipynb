{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Biodegradebility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Goal of this project is to use QSAR-Data (Quantitative Structure Ability Relationship) from cemical Compounds and classify biodegradable and non biodegradable substances. Since compounds can last hundreds of years before being decomposed, degradability experiments will take time accordingly. This is where the approach of QSAR begins to shine. Just by looking at relatively quick to obtain molecular properties, the molecules behaviour (in this case biodegradability) can be estimated. Thus helping to ensure correct disposal of chemicals and saving the environment, while also reducing expensive longterm experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Project i will:\n",
    "* use my domain knowledge in chemistry to engineer sophisticated features\n",
    "* explore multiple classification models\n",
    "* apply and tune a logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Dataset Description : https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') #ignore warning to imporve readability\n",
    "pd.set_option(\"display.max_columns\", 300) #make every column visible\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom functions\n",
    "from functions import evaluate_classifier #plot confusion matrix and evaluate model using multible test metrics\n",
    "from functions import plot_coefs #plot coefficients for Regression models\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10,5] #setting for correct size of confusion matrix\n",
    "\n",
    "#Initialize storing for results, in order to easily compare multiple models\n",
    "results_dict_list = []\n",
    "results_model_names_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m                              README.md\r\n",
      "LICENSE                           \u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "\u001b[34mPictures\u001b[m\u001b[m                          biodeg.csv\r\n",
      "Presentation Biodegradability.pdf functions.py\r\n",
      "Project 4 Biodegradables.ipynb    lgR_model_save.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls #check that all needed files are in the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"biodeg.csv\", sep = \";\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919</td>\n",
       "      <td>2.6909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.106</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.932</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949</td>\n",
       "      <td>1.591</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170</td>\n",
       "      <td>2.1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.461</td>\n",
       "      <td>1.393</td>\n",
       "      <td>8.723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.214</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.315</td>\n",
       "      <td>1.967</td>\n",
       "      <td>0</td>\n",
       "      <td>7.257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932</td>\n",
       "      <td>3.2512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.279</td>\n",
       "      <td>2.585</td>\n",
       "      <td>9.110</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.942</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.417</td>\n",
       "      <td>0</td>\n",
       "      <td>7.601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.7098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0.918</td>\n",
       "      <td>6.594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0</td>\n",
       "      <td>8.361</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.046</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236</td>\n",
       "      <td>3.3944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>3.449</td>\n",
       "      <td>2.753</td>\n",
       "      <td>9.528</td>\n",
       "      <td>2</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.985</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>10.348</td>\n",
       "      <td>5.588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0</td>\n",
       "      <td>8.003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1   2   3   4   5   6     7   8   9   10     11     12     13  \\\n",
       "0  3.919  2.6909   0   0   0   0   0  31.4   2   0   0  0.000  3.106  2.550   \n",
       "1  4.170  2.1144   0   0   0   0   0  30.8   1   1   0  0.000  2.461  1.393   \n",
       "2  3.932  3.2512   0   0   0   0   0  26.7   2   4   0  0.000  3.279  2.585   \n",
       "3  3.000  2.7098   0   0   0   0   0  20.0   0   2   0  0.000  2.100  0.918   \n",
       "4  4.236  3.3944   0   0   0   0   0  29.4   2   4   0 -0.271  3.449  2.753   \n",
       "\n",
       "      14  15     16     17  18  19  20     21  22  23  24  25     26     27  \\\n",
       "0  9.002   0  0.960  1.142   0   0   0  1.201   0   0   0   0  1.932  0.011   \n",
       "1  8.723   1  0.989  1.144   0   0   0  1.104   1   0   0   0  2.214 -0.204   \n",
       "2  9.110   0  1.009  1.152   0   0   0  1.092   0   0   0   0  1.942 -0.008   \n",
       "3  6.594   0  1.108  1.167   0   0   0  1.024   0   0   0   0  1.414  1.073   \n",
       "4  9.528   2  1.004  1.147   0   0   0  1.137   0   0   0   0  1.985 -0.002   \n",
       "\n",
       "   28      29     30  31  32  33  34     35     36  37     38  39  40  41  \n",
       "0   0   0.000  4.489   0   0   0   0  2.949  1.591   0  7.253   0   0  RB  \n",
       "1   0   0.000  1.542   0   0   0   0  3.315  1.967   0  7.257   0   0  RB  \n",
       "2   0   0.000  4.891   0   0   0   1  3.076  2.417   0  7.601   0   0  RB  \n",
       "3   0   8.361  1.333   0   0   0   1  3.046  5.000   0  6.690   0   0  RB  \n",
       "4   0  10.348  5.588   0   0   0   0  3.351  2.405   0  8.003   0   0  RB  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #check columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame is missing column description. These have to be added from the Scource Website "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Columns in the dataset are highly abrrivieated , a longer desciption is needed to truly understand the data. The description can originally be obtained here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation#\n",
    "\n",
    "For easy sorting functionality and a quick lookup the description is copied from the website and turned into a Pandas DataFrame using the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Data/description_raw.txt\", \"r\")\n",
    "description_df = pd.DataFrame(columns = [\"short\", \"description\"])\n",
    "info = \"start\"\n",
    "while len(info):\n",
    "    info = f.readline()\n",
    "    if not info: \n",
    "        break\n",
    "    info = info.split(\") \",1)[1][:-2]\n",
    "    short = info.split(\": \",1)[0]\n",
    "    #description = info.split(\": \",1)[1]\n",
    "    description_df.loc[len(description_df)] = info.split(\": \",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description is saved, to easily share it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description_df.to_csv(\"data/description.csv\", index=False)\n",
    "description_df = pd.read_csv(\"Data/description.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B01[C-Br]</td>\n",
       "      <td>Presence/absence of C - Br at topological dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B03[C-Cl]</td>\n",
       "      <td>Presence/absence of C - Cl at topological dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B04[C-Br]</td>\n",
       "      <td>Presence/absence of C - Br at topological dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C%</td>\n",
       "      <td>Percentage of C atoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>C-026</td>\n",
       "      <td>R--CX--R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F01[N-N]</td>\n",
       "      <td>Frequency of N-N at topological distance 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>F02[C-N]</td>\n",
       "      <td>Frequency of C - N at topological distance 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F03[C-N]</td>\n",
       "      <td>Frequency of C-N at topological distance 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>F03[C-O]</td>\n",
       "      <td>Frequency of C - O at topological distance 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F04[C-N]</td>\n",
       "      <td>Frequency of C-N at topological distance 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HyWi_B(m)</td>\n",
       "      <td>Hyper-Wiener-like index (log function) from Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J_Dz(e)</td>\n",
       "      <td>Balaban-like index from Barysz matrix weighted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Lopping centric index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Me</td>\n",
       "      <td>Mean atomic Sanderson electronegativity (scale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Mean first ionization potential (scaled on Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>N-073</td>\n",
       "      <td>Ar2NH / Ar3N / Ar2N-Al / R..N..R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NssssC</td>\n",
       "      <td>Number of atoms of type ssssC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Psi_i_1d</td>\n",
       "      <td>Intrinsic state pseudoconnectivity index - typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Psi_i_A</td>\n",
       "      <td>Intrinsic state pseudoconnectivity index - typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SM6_B(m)</td>\n",
       "      <td>Spectral moment of order 6 from Burden matrix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SM6_L</td>\n",
       "      <td>Spectral moment of order 6 from Laplace matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SdO</td>\n",
       "      <td>Sum of dO E-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SdssC</td>\n",
       "      <td>Sum of dssC E-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SpMax_A</td>\n",
       "      <td>Leading eigenvalue from adjacency matrix (Lova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SpMax_B(m)</td>\n",
       "      <td>Leading eigenvalue from Burden matrix weighted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpMax_L</td>\n",
       "      <td>Leading eigenvalue from Laplace matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SpPosA_B(p)</td>\n",
       "      <td>Normalized spectral positive sum from Burden m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TI2_L</td>\n",
       "      <td>Second Mohar index from Laplace matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>experimental class</td>\n",
       "      <td>ready biodegradable (RB) and not ready biodegr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>nArCOOR</td>\n",
       "      <td>Number of esters (aromatic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nArNO2</td>\n",
       "      <td>Number of nitro groups (aromatic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nCIR</td>\n",
       "      <td>Number of circuits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nCRX3</td>\n",
       "      <td>Number of CRX3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nCb-</td>\n",
       "      <td>Number of substituted benzene C(sp2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nCp</td>\n",
       "      <td>Number of terminal primary C(sp3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nCrt</td>\n",
       "      <td>Number of ring tertiary C(sp3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nHDon</td>\n",
       "      <td>Number of donor atoms for H-bonds (N and O)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nHM</td>\n",
       "      <td>Number of heavy atoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>nN</td>\n",
       "      <td>Number of Nitrogen atoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nN-N</td>\n",
       "      <td>Number of N hydrazines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nO</td>\n",
       "      <td>Number of oxygen atoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nX</td>\n",
       "      <td>Number of halogen atoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 short                                        description\n",
       "23           B01[C-Br]  Presence/absence of C - Br at topological dist...\n",
       "24           B03[C-Cl]  Presence/absence of C - Cl at topological dist...\n",
       "28           B04[C-Br]  Presence/absence of C - Br at topological dist...\n",
       "7                   C%                              Percentage of C atoms\n",
       "32               C-026                                           R--CX--R\n",
       "3             F01[N-N]         Frequency of N-N at topological distance 1\n",
       "33            F02[C-N]       Frequency of C - N at topological distance 2\n",
       "10            F03[C-N]         Frequency of C-N at topological distance 3\n",
       "15            F03[C-O]       Frequency of C - O at topological distance 3\n",
       "4             F04[C-N]         Frequency of C-N at topological distance 4\n",
       "12           HyWi_B(m)  Hyper-Wiener-like index (log function) from Bu...\n",
       "1              J_Dz(e)  Balaban-like index from Barysz matrix weighted...\n",
       "13                 LOC                              Lopping centric index\n",
       "16                  Me  Mean atomic Sanderson electronegativity (scale...\n",
       "17                  Mi  Mean first ionization potential (scaled on Car...\n",
       "25               N-073                   Ar2NH / Ar3N / Ar2N-Al / R..N..R\n",
       "5               NssssC                      Number of atoms of type ssssC\n",
       "27            Psi_i_1d  Intrinsic state pseudoconnectivity index - typ...\n",
       "36             Psi_i_A  Intrinsic state pseudoconnectivity index - typ...\n",
       "38            SM6_B(m)  Spectral moment of order 6 from Burden matrix ...\n",
       "14               SM6_L     Spectral moment of order 6 from Laplace matrix\n",
       "29                 SdO                                 Sum of dO E-states\n",
       "11               SdssC                               Sum of dssC E-states\n",
       "26             SpMax_A  Leading eigenvalue from adjacency matrix (Lova...\n",
       "35          SpMax_B(m)  Leading eigenvalue from Burden matrix weighted...\n",
       "0              SpMax_L             Leading eigenvalue from Laplace matrix\n",
       "21         SpPosA_B(p)  Normalized spectral positive sum from Burden m...\n",
       "30               TI2_L             Second Mohar index from Laplace matrix\n",
       "41  experimental class  ready biodegradable (RB) and not ready biodegr...\n",
       "39             nArCOOR                        Number of esters (aromatic)\n",
       "19              nArNO2                  Number of nitro groups (aromatic)\n",
       "22                nCIR                                 Number of circuits\n",
       "20               nCRX3                                     Number of CRX3\n",
       "6                 nCb-               Number of substituted benzene C(sp2)\n",
       "8                  nCp                  Number of terminal primary C(sp3)\n",
       "31                nCrt                     Number of ring tertiary C(sp3)\n",
       "34               nHDon        Number of donor atoms for H-bonds (N and O)\n",
       "2                  nHM                              Number of heavy atoms\n",
       "37                  nN                           Number of Nitrogen atoms\n",
       "18                nN-N                             Number of N hydrazines\n",
       "9                   nO                             Number of oxygen atoms\n",
       "40                  nX                            Number of halogen atoms"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_df.sort_values(\"short\") #lookup table for Column descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = description_df.short #assign describtions to column header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>short</th>\n",
       "      <th>SpMax_L</th>\n",
       "      <th>J_Dz(e)</th>\n",
       "      <th>nHM</th>\n",
       "      <th>F01[N-N]</th>\n",
       "      <th>F04[C-N]</th>\n",
       "      <th>NssssC</th>\n",
       "      <th>nCb-</th>\n",
       "      <th>C%</th>\n",
       "      <th>nCp</th>\n",
       "      <th>nO</th>\n",
       "      <th>F03[C-N]</th>\n",
       "      <th>SdssC</th>\n",
       "      <th>HyWi_B(m)</th>\n",
       "      <th>LOC</th>\n",
       "      <th>SM6_L</th>\n",
       "      <th>F03[C-O]</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mi</th>\n",
       "      <th>nN-N</th>\n",
       "      <th>nArNO2</th>\n",
       "      <th>nCRX3</th>\n",
       "      <th>SpPosA_B(p)</th>\n",
       "      <th>nCIR</th>\n",
       "      <th>B01[C-Br]</th>\n",
       "      <th>B03[C-Cl]</th>\n",
       "      <th>N-073</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>Psi_i_1d</th>\n",
       "      <th>B04[C-Br]</th>\n",
       "      <th>SdO</th>\n",
       "      <th>TI2_L</th>\n",
       "      <th>nCrt</th>\n",
       "      <th>C-026</th>\n",
       "      <th>F02[C-N]</th>\n",
       "      <th>nHDon</th>\n",
       "      <th>SpMax_B(m)</th>\n",
       "      <th>Psi_i_A</th>\n",
       "      <th>nN</th>\n",
       "      <th>SM6_B(m)</th>\n",
       "      <th>nArCOOR</th>\n",
       "      <th>nX</th>\n",
       "      <th>experimental class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919</td>\n",
       "      <td>2.6909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.106</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.932</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949</td>\n",
       "      <td>1.591</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170</td>\n",
       "      <td>2.1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.461</td>\n",
       "      <td>1.393</td>\n",
       "      <td>8.723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.214</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.315</td>\n",
       "      <td>1.967</td>\n",
       "      <td>0</td>\n",
       "      <td>7.257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932</td>\n",
       "      <td>3.2512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.279</td>\n",
       "      <td>2.585</td>\n",
       "      <td>9.110</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.942</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.417</td>\n",
       "      <td>0</td>\n",
       "      <td>7.601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.7098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0.918</td>\n",
       "      <td>6.594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0</td>\n",
       "      <td>8.361</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.046</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236</td>\n",
       "      <td>3.3944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>3.449</td>\n",
       "      <td>2.753</td>\n",
       "      <td>9.528</td>\n",
       "      <td>2</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.985</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>10.348</td>\n",
       "      <td>5.588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0</td>\n",
       "      <td>8.003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "short  SpMax_L  J_Dz(e)  nHM  F01[N-N]  F04[C-N]  NssssC  nCb-    C%  nCp  nO  \\\n",
       "0        3.919   2.6909    0         0         0       0     0  31.4    2   0   \n",
       "1        4.170   2.1144    0         0         0       0     0  30.8    1   1   \n",
       "2        3.932   3.2512    0         0         0       0     0  26.7    2   4   \n",
       "3        3.000   2.7098    0         0         0       0     0  20.0    0   2   \n",
       "4        4.236   3.3944    0         0         0       0     0  29.4    2   4   \n",
       "\n",
       "short  F03[C-N]  SdssC  HyWi_B(m)    LOC  SM6_L  F03[C-O]     Me     Mi  nN-N  \\\n",
       "0             0  0.000      3.106  2.550  9.002         0  0.960  1.142     0   \n",
       "1             0  0.000      2.461  1.393  8.723         1  0.989  1.144     0   \n",
       "2             0  0.000      3.279  2.585  9.110         0  1.009  1.152     0   \n",
       "3             0  0.000      2.100  0.918  6.594         0  1.108  1.167     0   \n",
       "4             0 -0.271      3.449  2.753  9.528         2  1.004  1.147     0   \n",
       "\n",
       "short  nArNO2  nCRX3  SpPosA_B(p)  nCIR  B01[C-Br]  B03[C-Cl]  N-073  SpMax_A  \\\n",
       "0           0      0        1.201     0          0          0      0    1.932   \n",
       "1           0      0        1.104     1          0          0      0    2.214   \n",
       "2           0      0        1.092     0          0          0      0    1.942   \n",
       "3           0      0        1.024     0          0          0      0    1.414   \n",
       "4           0      0        1.137     0          0          0      0    1.985   \n",
       "\n",
       "short  Psi_i_1d  B04[C-Br]     SdO  TI2_L  nCrt  C-026  F02[C-N]  nHDon  \\\n",
       "0         0.011          0   0.000  4.489     0      0         0      0   \n",
       "1        -0.204          0   0.000  1.542     0      0         0      0   \n",
       "2        -0.008          0   0.000  4.891     0      0         0      1   \n",
       "3         1.073          0   8.361  1.333     0      0         0      1   \n",
       "4        -0.002          0  10.348  5.588     0      0         0      0   \n",
       "\n",
       "short  SpMax_B(m)  Psi_i_A  nN  SM6_B(m)  nArCOOR  nX experimental class  \n",
       "0           2.949    1.591   0     7.253        0   0                 RB  \n",
       "1           3.315    1.967   0     7.257        0   0                 RB  \n",
       "2           3.076    2.417   0     7.601        0   0                 RB  \n",
       "3           3.046    5.000   0     6.690        0   0                 RB  \n",
       "4           3.351    2.405   0     8.003        0   0                 RB  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: write what you're analyzing here, each output should be explained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write full sentences/bullet points. always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([\"RB\",\"NRB\"],[1,0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"experimental class\": \"degradable\"}, inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cleaned Data\n",
    "#df.to_csv(\"biodeg_cleaned.csv\", index=False)\n",
    "#df = pd.read_csv(\"biodeg_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Acronyms have to be explained before you use them. always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: headline/explanation missing - what are you doing here (and why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Class Inbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"degradable\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRB = 0 --> Not Biodegradable\n",
    "# RB = 1 --> Biodegradable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> Class inbalance acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Multicorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abs(df.corr()[\"degradable\"]).sort_values(ascending = False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().applymap(lambda x: x if abs(x)>.90 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Multicorrelated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_drop = [\"SM6_L\",\"SpMax_A\",\"SM6_B(m)\"]\n",
    "corr_keep = list(set(df.columns)-set(corr_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparision between feature distribution in the two target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Target True and False\n",
    "bio_df = df.loc[df[\"degradable\"] == 1]\n",
    "no_bio_df = df.loc[df[\"degradable\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = corr_keep\n",
    "for col in list(filter(lambda x: x != \"diagnosis\", features)):\n",
    "    sns.distplot(bio_df[col] ,label = \"degradable\", color = \"g\")\n",
    "    sns.distplot(no_bio_df[col], label = \"non degradable\" )\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If feature has more then 10 unique values it is probably not categorical, but continuous.\n",
    "features = corr_keep\n",
    "for col in features:\n",
    "    print(col)\n",
    "    valc = df[col].value_counts(normalize = True)\n",
    "    if len(valc)<10:\n",
    "        print(valc)\n",
    "    else:\n",
    "        print(\"probably not categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of EDA\n",
    "\n",
    "The following Features lead to a high speration of the target classes. \n",
    "+ SpPosA_B(p)\n",
    "+ HyWi_B(m)\n",
    "+ C%\n",
    "+ SpMax_B(m)\n",
    "+ SpMax_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Heavy Meatals\n",
    "This feature will be recoded to inform about heavy Metal atoms:\n",
    "+ It is most likely that in degradable organic compounds there is only one heavy metal present (nHM =1) in as a single central atom in a chemical complex bound.\n",
    "+ If nHM exeeds one a compound will be either anorganic or of high toxicity and therefore lead to low biodegradability. (nHM >1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nHM(x):\n",
    "    if x == 0:\n",
    "        return \"light\"\n",
    "    if x == 1:\n",
    "        return \"functional\"\n",
    "    if x >1:\n",
    "        return \"heavy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nHM_enc\"] = df[\"nHM\"].apply(encode_nHM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping shows that there is in fact a certain seperation of target classes in using this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby([\"nHM_enc\",\"degradable\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nHM_dummies = pd.get_dummies(df[\"nHM_enc\"],\"nHM\").drop(\"nHM_light\",axis = 1)\n",
    "df = pd.concat([df,nHM_dummies], axis = 1).drop(\"nHM_enc\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecule Shape\n",
    "The number of terminal C-Atoms informs about the overall shape of a moleculy, highly branched meolekules are expected to be less degradable, because the branches make it harder for enzymes to connect to the molecule and deconstruct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_class(x):\n",
    "    if x == 0:\n",
    "        return \"ring\"\n",
    "    if x == 1:\n",
    "        return \"semi_ring\"\n",
    "    if x == 2:\n",
    "        return \"linear\"\n",
    "    if x >2:\n",
    "        return \"branched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"molShape\"] = df[\"nCp\"].apply(shape_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping shows that espeacially branched and ring shaped molecules provide a good seperation between target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby([\"molShape\",\"degradable\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mS_dummies = pd.get_dummies(df[\"molShape\"],\"mS\").drop(\"mS_semi_ring\",axis = 1)\n",
    "df = pd.concat([df,mS_dummies], axis = 1).drop(\"molShape\",axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esther\n",
    "Having a Esther group in the molecule provides an easy breaking point due to hydrolysis. Therefore degradability should improve in esthers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"esther\"] = df.nArCOOR.apply(lambda x: 1 if x>0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping shows s seperation but the data lecks observations with molecule containing esther groups. Therefor the effect of this festure will be hardly recognisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby([\"esther\",\"degradable\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/Load engineered DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"Data/df_engineered.csv\", index=False)\n",
    "#df = pd.read_csv(\"Data/df_engineered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove colinear columns as identified in EDA\n",
    "keep = list(set(df.columns) - set(corr_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Target and Feature Variables and perform standard 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.degradable\n",
    "X = df[keep].drop(\"degradable\", axis = 1)\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,y ,random_state=42 , test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2,include_bias = False)\n",
    "poly.fit(X_train)\n",
    "X_train_poly = (pd.DataFrame(poly.transform(X_train),columns = poly.get_feature_names(X_train.columns)))\n",
    "X_test_poly = (pd.DataFrame(poly.transform(X_test),columns = poly.get_feature_names(X_train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Features to improve Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_poly = StandardScaler()\n",
    "scaler_poly.fit(X_train_poly)\n",
    "X_train_poly = pd.DataFrame(scaler_poly.transform(X_train_poly),columns = X_train_poly.columns)\n",
    "X_test_poly = pd.DataFrame(scaler_poly.transform(X_test_poly),columns = X_train_poly.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale Features to improve Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler_lin = StandardScaler()\n",
    "scaler_lin.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler_lin.transform(X_train),columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler_lin.transform(X_test),columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_cols_all = X_train.columns\n",
    "\n",
    "#X_train.to_csv(\"Data/X_train_lin_scaled.csv\", index=False)\n",
    "#X_test.to_csv(\"Data/X_test_lin_scaled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection will be performed using Lasso Penalty in a Logistic Regression Classifier Model.\n",
    "The target metric wills be:\n",
    "+ Precission (because predicting biodegradability when the molecule is not (False Positive) is worse than predicting nondegradability allthough the molecule is degradable.\n",
    "+ Specificity (to compare Model performance with Values in the Scource Paper)\n",
    "+ Sensitivity (to compare Model performance with Values in the Scource Paper)\n",
    "+ F1 (to get an overall scoring)\n",
    "\n",
    "Features are dropped if dropping them does not significantly lower model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logReg_base = LogisticRegression(random_state=42)\n",
    "\n",
    "logReg_base.fit(X_train,y_train)\n",
    "logReg_base_pred = logReg_base.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,logReg_base_pred, normalize=True))\n",
    "results_model_names_list.append(\"LogR_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_base_l1 = LogisticRegression(solver = \"saga\", penalty = \"l1\", C = 0.7, random_state=42)\n",
    "\n",
    "logReg_base_l1.fit(X_train,y_train)\n",
    "logReg_base_l1_pred = logReg_base_l1.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,logReg_base_l1_pred, normalize=True))\n",
    "drop_l1 = plot_coefs(X_train,logReg_base_l1)\n",
    "results_model_names_list.append(\"LogR_lin_l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_keep = list(set(X_train.columns) - set(drop_l1))\n",
    "l1_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "forest_base.fit(X_train,y_train)\n",
    "forest_base_pred = forest_base.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,forest_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"RandFor_lin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_base = KNeighborsClassifier(n_neighbors = 13)\n",
    "\n",
    "KNN_base.fit(X_train,y_train)\n",
    "KNN_base_pred = KNN_base.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,KNN_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"KNN_lin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = logReg_base_l1\n",
    "clf2 = forest_base\n",
    "clf3 = KNN_base\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('KNN', clf3)], voting='hard')\n",
    "eclf.fit(X_train,y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'KNN', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(\"F1: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf_base_pred = eclf.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,eclf_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"Ensemble_lin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_poly.copy()\n",
    "X_test = X_test_poly.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_base_l1_poly = LogisticRegression(solver = \"saga\", penalty = \"l1\", C = 1, random_state=42)\n",
    "\n",
    "logReg_base_l1_poly.fit(X_train_poly,y_train)\n",
    "logReg_base_l1_poly_pred = logReg_base_l1_poly.predict(X_test_poly)\n",
    "results_dict_list.append(evaluate_classifier(y_test,logReg_base_l1_poly_pred, normalize=True))\n",
    "drop_l1_poly = plot_coefs(X_train_poly,logReg_base_l1_poly)\n",
    "results_model_names_list.append(\"LogR_poly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "forest_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "forest_base.fit(X_train,y_train)\n",
    "forest_base_pred = forest_base.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,forest_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"RandFor_poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_featimp_df = pd.DataFrame(forest_base.feature_importances_, index = X_train.columns)\n",
    "sorted_rfc = rfc_featimp_df.sort_values(by = 0, ascending = False)\n",
    "rfc_add = list(sorted_rfc[sorted_rfc[0]>0.01].head(3).index)\n",
    "rfc_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KNN_base = KNeighborsClassifier(n_neighbors = 13)\n",
    "\n",
    "KNN_base.fit(X_train,y_train)\n",
    "KNN_base_pred = KNN_base.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,KNN_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"KNN_poly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf1 = logReg_base_l1\n",
    "clf2 = forest_base\n",
    "clf3 = KNN_base\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('KNN', clf3)], voting='hard')\n",
    "eclf.fit(X_train,y_train)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'KNN', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(\"F1: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eclf_base_pred = eclf.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(y_test,eclf_base_pred, normalize=True));\n",
    "results_model_names_list.append(\"Ensemble_poly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import compare_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare model score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out_df = compare_models(results_dict_list, results_model_names_list )\n",
    "out_df[\"sum\"] = out_df.iloc[:,0:4].sum(axis = 1)\n",
    "out_df.drop(\"confusion_matrix\", axis = 1).applymap(lambda x: round(x,2)).sort_values(by = \"sum\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.sort_values(by = \"sum\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = [\"accuracy\",\"precission\",\"sensitivity\",\"f_1\"]\n",
    "\n",
    "for col in res_cols:\n",
    "    plt.plot(out_df.index, out_df[col], label = col)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of Model Selection\n",
    "Both Logistic Regression models without polynomial Features perform quite well, thus Logistic Regression is chosen for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select linear Features, that were not restricted to a coefficient of zero by lasso selection and reselect Training and Test Feature accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(l1_keep).union((lin_cols_all)))\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_poly[features]\n",
    "X_test = X_test_poly[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom scoring is chosen to best fit all of the specified metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(y_true,y_pred):\n",
    "    f1 = metrics.f1_score(y_true,y_pred)\n",
    "    acc = metrics.accuracy_score(y_true,y_pred)\n",
    "    prec = metrics.precision_score(y_true,y_pred)\n",
    "    sens = metrics.recall_score(y_true,y_pred)\n",
    "    return f1+acc+prec+sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and run gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgR_20 = LogisticRegression(random_state = 42)\n",
    "param_grid = {\"solver\":[\"liblinear\",\"saga\"],\n",
    "          \"penalty\":[\"l1\",\"l2\"],\n",
    "          \"C\":np.arange(0.1,1,0.05),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logR = GridSearchCV(estimator = lgR_20,\n",
    "                         param_grid = param_grid,\n",
    "                         scoring = make_scorer(custom_scorer),\n",
    "                         cv = 5,\n",
    "                         verbose = 4,\n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logR.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_logR_pred = grid_logR.best_estimator_.predict(X_test)\n",
    "evaluate_classifier(grid_logR_pred,y_test, normalize=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_logR.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgR_2 = LogisticRegression(solver = \"liblinear\", penalty = \"l2\", C = 0.9, random_state=42)\n",
    "lgR_2.fit(X_train,y_train)\n",
    "lgR_2_pred = lgR_2.predict(X_test)\n",
    "results_dict_list.append(evaluate_classifier(lgR_2_pred,y_test, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allthough Model performance did not improve with running the gridseach, the cross validation used provied a more robust model. Hence the Final model as seen above is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect final feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zeros = plot_coefs(X_train,lgR_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zeros_df = plot_coefs(X_train,lgR_2,return_nulls = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank top 20 most important features and display them for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df = zeros_df.sort_values(by = \"abs\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df[\"rank\"] = list(range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_df[[\"rank\",\"coeff\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"lgR_model_save.pickle\" ,\"wb\") as f:\n",
    "    #pickle.dump(lgR_2,f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
